{"cells":[{"cell_type":"markdown","metadata":{"id":"7jW7yNoy-2hW"},"source":["## A Case Study on Descriptive Statistics for Data Science"]},{"cell_type":"markdown","metadata":{"id":"JLtmgpaZHu7V"},"source":["## Introduction\n","\n","Descriptive statistics refers to the study of numerical and graphical methods to describe and present the data. By summarising the provided sample set or population of data, it characterises the data and aids in our understanding of its characteristics. In short, the type of statistics used to summarise and characterise the dataset is called descriptive statistics. It is employed to explain the properties of data."]},{"cell_type":"markdown","metadata":{"id":"-QqQQnogq6p1"},"source":["## Describing the dataset\n","\n","This dataset offers nutrition information for around 8.8k different types of food. The titles of the features are self-explanatory, therefore I won't go into detail about them. Access the dataset : [nutrition data](https://colab.research.google.com/drive/1szFExQLNstWDneCvsOQjd-xheAL7ZmmN?usp=sharing)\n","\n","\n","<br>\n","\n","**name** : Name of the foods\n"," \n","**calories** : Total ammount of calories present in the food\n"," \n","**total_fat** : Total fat ammount present in the food\n","  \n","**saturated_fat** : Total ammount of saturated_fat present\n"," \n","**cholesterol** : Total ammount of cholesterol present\n"," \n","**sodium** : Total ammount of sodium present\n"," \n","**choline** : Total ammount of choline present\n"," \n","**folate** : Total ammount of folate present\n"," \n","**folic_acid** : Total ammount of folic_acid present\n"," \n","**niacin** : Total ammount of niacin present\n"," \n","**pantothenic_acid** : Total ammount of pantothenic_acid present\n"," \n","**riboflavin** : Total ammount of riboflavin present\n"," \n","**thiamin** : Total ammount of thiamin present\n"," \n","**vitamin_a** : Total ammount of vitamin_a present\n"," \n","**vitamin_a_rae** : Total ammount of vitamin_a_rae present\n"," \n","**carotene_alpha** : Total ammount of carotene_alpha present\n"," \n","**carotene_beta** : Total ammount of carotene_beta present\n"," \n","**cryptoxanthin_beta** : Total ammount of cryptoxanthin_beta present\n"," \n","**lutein_zeaxanthin** : Total ammount of lutein_zeaxanthin present\n"," \n","**lucopene** : Total ammount of lucopene present\n"," \n","**vitamin_b12** : Total ammount of vitamin_b12 present\n"," \n","**vitamin_b6** : Total ammount of vitamin_b6 present\n"," \n","**vitamin_c** : Total ammount of vitamin_c present\n"," \n","**vitamin_d** : Total ammount of vitamin_d present\n"," \n","**vitamin_e** : Total ammount of vitamin_e present\n"," \n","**tocopherol_alpha** : Total ammount of tocopherol_alpha present\n"," \n","**vitamin_k** : Total ammount of vitamin_k present\n"," \n","**calcium** : Total ammount of calcium present\n"," \n","**copper** : Total ammount of copper present\n"," \n","**irom** : Total ammount of irom present\n"," \n","**magnesium** : Total ammount of magnesium present\n"," \n","**manganese** : Total ammount of manganese present\n"," \n","**phosphorous** : Total ammount of phosphorous present\n"," \n","**potassium** : Total ammount of potassium present\n"," \n","**selenium** : Total ammount of selenium present\n"," \n","**zink** : Total ammount of zink present\n"," \n","**protein** : Total ammount of protein present\n"," \n","**alanine** : Total ammount of alanine present\n"," \n","**arginine** : Total ammount of arginine present\n"," \n","**aspartic_acid** : Total ammount of aspartic_acid present\n"," \n","**cystine** : Total ammount of cystine present\n"," \n","**glutamic_acid** : Total ammount of glutamic_acid present\n"," \n","**glycine** : Total ammount of glycine present\n"," \n","**histidine** : Total ammount of histidine present\n"," \n","**hydroxyproline** : Total ammount of hydroxyproline present\n"," \n","**isoleucine** : Total ammount of isoleucine present\n"," \n","**leucine** : Total ammount of leucine present\n"," \n","**lysine** : Total ammount of lysine present\n"," \n","**methionine** : Total ammount of methionine present\n"," \n","**phenylalanine** : Total ammount of phenylalanine present\n"," \n","**proline** : Total ammount of proline present\n"," \n","**serine** : Total ammount of serine present\n"," \n","**threonine** : Total ammount of threonine present\n"," \n","**tryptophan** : Total ammount of tryptophan present\n"," \n","**tyrosine** : Total ammount of tyrosine present\n"," \n","**valine** : Total ammount of valine present\n"," \n","**carbohydrate** : Total ammount of carbohydrate present\n"," \n","**fiber** : Total ammount of fiber present\n"," \n","**sugars** : Total ammount of sugars present\n"," \n","**fructose** : Total ammount of fructose present\n"," \n","**galactose** : Total ammount of galactose present\n"," \n","**glucose** : Total ammount of glucose present\n"," \n","**lactose** : Total ammount of lactose present\n"," \n","**maltose** : Total ammount of maltose present\n"," \n","**sucrose** : Total ammount of sucrose present\n"," \n","**fat** : Total ammount of fat present\n"," \n","**saturated_fatty_acids** : Total ammount of saturated_fatty_acids present\n"," \n","**monounsaturated_fatty_acids** : Total ammount of monounsaturated_fatty_acids present\n"," \n","**polyunsaturated_fatty_acids** : Total ammount of polyunsaturated_fatty_acids present\n"," \n","**fatty_acids_total_trans** : Total ammount of fatty_acids_total_trans present\n"," \n","**alcohol** : Total ammount of alcohol present\n"," \n","**ash** : Total ammount of ash present\n"," \n","**caffeine** : Total ammount of caffeine present\n"," \n","**theobromine** : Total ammount of theobromine present\n"," \n","**water** : Total ammount of water present\n"," "]},{"cell_type":"markdown","metadata":{"id":"pAtBnPZ4rGDk"},"source":["## Table of Content\n","\n","1. **[Import Libraries](#lib)**\n","2. **[Data Preparation](#prep)**\n","    - 2.1 - **[Understand the Data](#read)**\n","    - 2.2 - **[Remove Insignificant Variables](#rmv)**\n","    - 2.3 - **[Missing Value Analysis and Treatment](#null)**\n","    - 2.4 - **[Duplicate Entries Analysis and Treatment](#dupl)**\n","    - 2.5 - **[Data Cleaining](#cleaning)** \n","    - 2.6 - **[Outlier Analysis and Treatment](#outlier)** \n","3.**[Descriptive Statistics](#ds)** \n","    - 3.1 - **[Measures of Central tendencies](#ctd)**\n","        - 3.1.1 - **[Mean](#mn)**\n","        - 3.1.2 - **[Median](#mdn)**\n","        - 3.1.3 - **[Mode](#md)**\n","    - 3.2 - **[Measures of Dispersion](#dd)**\n","        - 3.2.1 - **[Range](#rn)**\n","        - 3.2.2 - **[standard Deviation](#sd)**\n","        - 3.2.3 - **[Variance](#var)**\n","        - 3.2.4 - **[Correlation](#cor)**\n","5. **[Visualization](#dv)**\n","    - 5.1 - **[Histogram](#hist)**\n","    - 5.2 - **[Count Plot](#count)**\n","    - 5.3 - **[Skewness and Kurtosis](#sk)**\n","    - 5.4 - **[Scatter Plot](#sp)**\n","    - 5.5 - **[Density Plot](#dp)**\n","    - 5.6 - **[Box Plot](#bp)**\n","    - 5.7 - **[Boxen Plot](#bxp)**\n","    - 5.8 - **[Bar Plot](#barp)**"]},{"cell_type":"markdown","metadata":{"id":"Jtfm_MwdH7KA"},"source":["<a id=\"lib\"></a>\n","# 1. Import Libraries\n","\n","\n","Here we are importing the libraries that we will be using."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["'install' is not recognized as an internal or external command,\n","operable program or batch file.\n"]}],"source":["pip install plotly.express"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"l4N-MEl4uPIv"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from scipy import stats\n","# import plotly.express as px"]},{"cell_type":"markdown","metadata":{"id":"33lnlHpGvmZY"},"source":["<a id=\"prep\"></a>\n","# 2. Data Preparation"]},{"cell_type":"markdown","metadata":{"id":"zu04Uq__vYjp"},"source":["<a id=\"read\"></a>\n","## 2.1 Understand the Data\n","\n","**Loading the the dataset**\n"," \n","You can load dataframe using `read_csv()` method from pandas."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":403},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1673381746147,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"mXMwzJpauzjl","outputId":"bf1bf0d4-961d-4173-e09b-40ca7c43fcf8"},"outputs":[],"source":["df = pd.read_csv('nutrition_1.csv')\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"c-LFfKAfJIjW"},"source":["Here we are loding the `csv` files as pandas dataframe."]},{"cell_type":"markdown","metadata":{"id":"4iz99rmxu_rp"},"source":["**Size of datframe**\n","\n","You can find size of dataframe using the `shape` attribute of the dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1673381747363,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"tBL7ngWRu_U-","outputId":"1fa4a7fe-a5c3-4954-8468-0c237a04063f"},"outputs":[],"source":["df.shape\n"]},{"cell_type":"markdown","metadata":{"id":"4DUtWkxDJOcJ"},"source":["We can determine the number of rows and columns observing the shape of the dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1673381747364,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"mhxnLBjUdWT9","outputId":"08353dac-08c0-437d-bd8a-4c543d998eaf"},"outputs":[],"source":["# name of the columns\n","a = list(df.columns)\n","for i in a:\n","  print(i)"]},{"cell_type":"markdown","metadata":{"id":"rhW4qC7SvIbK"},"source":["<a id=\"rmv\"></a>\n","## 2.2 Remove Insignificant Variables\n","\n","We'll be focusing on the numerical data and remove feature that contain any other form of data. Here we're removing the columns named \"Unamed: 0\", \"Unnamed: 0.1\", \"lucopene\" and \"Serving_Size\"which are not needed to get insights from the data\n","<br>\n","\n","Serving size is not necessary since for all records the serving size is same which is `100 g`\n","<br>\n","\n","lucopene is not necessary since for all records the serving size is same which is `0`"]},{"cell_type":"markdown","metadata":{"id":"RZ8FnoygKWK8"},"source":["you can drop columns usning `drop()` method.\n","You can read more about it on <a href=\"https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html\">This Link </a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9nuitP3vK7F"},"outputs":[],"source":["df.drop(['Unnamed: 0','Unnamed: 0.1','serving_size', 'lucopene'],axis=1,inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"LXzhPScUJiVE"},"source":["By dropping uncessary columns we can make statistical analyis easy and efficent.<br>\n","The size of the dataset decreases and so performance of the methods becomes faster."]},{"cell_type":"markdown","metadata":{"id":"0PIBwiu7whQu"},"source":["<a id=\"null\"></a>\n","## 2.3 Missing Value Analysis and Treatment"]},{"cell_type":"markdown","metadata":{"id":"7Z9CAjDfOZQB"},"source":["You can check whether the value is null value or not by using the method called as `isna()`.While the `sum()` method gives total number of null entries.\n","\n","You can read more about `isna()` on <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html\"> This link</a>."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":701,"status":"ok","timestamp":1673381751368,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"h7IQYFa4FvrF","outputId":"4ff25829-c2c4-4a4b-ef21-20f91fe0d877"},"outputs":[],"source":["null_per = pd.DataFrame({'count':df.isna().sum(),'Percentage':df.isna().sum()*100/8789})\n","null_per"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1673381751369,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"6Puj2rKdGy-u","outputId":"a7f250f2-0fe7-4779-d0c2-7600c0c2123d"},"outputs":[],"source":["null_per.Percentage.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"FGUGwd1mG5O5"},"source":["The feature saturated_fat has around 18% of null entries. As a significant chunk of the dataset is empty, we can impute the null values in the feature, saturated_fat.<br>\n","If dataset has outliers, mean imputation is not a good option. In such case, imputation with median is suggested."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"executionInfo":{"elapsed":724,"status":"ok","timestamp":1673381752756,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"1S9ANQjDHAog","outputId":"0c869200-c640-469f-f708-9b6dbc9f9356"},"outputs":[],"source":["# Check whether saturated_fat has outliers\n","sns.boxplot(df['saturated_fat'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"fVB77kh0H58k"},"source":["From above plot, we come to know that saturated_fat feature has many outliers, so impute the null values in the saturated_fat feature by median value of available values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Ex24C_mH99Y"},"outputs":[],"source":["df['saturated_fat'] = df['saturated_fat'].fillna(df['saturated_fat'].median())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1673381754283,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"NBPML3afIEpy","outputId":"0f5f9b66-a08f-477b-eb46-8e84553b9b22"},"outputs":[],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{"id":"GQV2T_VGIU-I"},"source":["The dataset is now completely free from the missing values."]},{"cell_type":"markdown","metadata":{"id":"oNKoKRMURAJ4"},"source":["<a id=\"dupl\"></a>\n","## 2.4 Duplicate Entries Analysis and Treatment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1673381756524,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"CgjXNj7dwrDo","outputId":"1703ea3c-2869-427b-ef00-d4ea01180bf4"},"outputs":[],"source":["df.duplicated().sum()"]},{"cell_type":"markdown","metadata":{"id":"7tbi49ijMViX"},"source":["There are no duplicate entries in the dataset. "]},{"cell_type":"markdown","metadata":{"id":"26BH5kGh7mAP"},"source":["<a id=\"cleaning\"></a>\n","## 2.5 Data Cleaning\n","\n","Many times we can face situations, where the data may not be in proper format. The data could contain use less noise which can throw our ML algorithms off when making predictions. We need to clean our data to overcome that\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":956},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673381758084,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"iauCfsdQ70av","outputId":"1823e481-8e85-41b1-e9d5-45bd3a180b7c"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1673381758687,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"B9FO9vb_I8U4","outputId":"11bcf89d-8256-4fc3-abc1-a8a817faa502"},"outputs":[],"source":["df.columns"]},{"cell_type":"markdown","metadata":{"id":"w2JlAS3wI-6U"},"source":["We can see that all columns other than name are numeric columns. However not all are formatted properly. Hence we must make these columns numerical and fit for analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1673381762702,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"IcWJ02AiJSwS","outputId":"31e73743-0bf2-4bef-8e72-aaefb00eada0"},"outputs":[],"source":["# get list of all column names\n","all_cols = df.columns\n","# get a list of numeric column names\n","num_cols = df.select_dtypes(['int32', 'int64', 'float32', 'float64'])\n","# get a list of unformated/unclean columns\n","unformated_cols = [x for x in all_cols if x not in num_cols]\n","# removing categorical columns\n","unformated_cols.remove('name')\n","\n","print(unformated_cols)\n","print(len(unformated_cols))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"elapsed":624,"status":"ok","timestamp":1673381763725,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"slPpI_BRNdk-","outputId":"9c415350-9546-460f-fff7-c4a564e678b4"},"outputs":[],"source":["for i in unformated_cols:\n","    # save new name of column to `new_col1 var\n","    new_col = f\"{i} ({df[i][0].split(' ')[-1]})\"\n","    # change column name\n","    df = df.rename(columns = {i: new_col})\n","    # format data\n","    df[new_col] = df[new_col].apply(lambda row: row.split(' ')[0])\n","    # change data type of the columns\n","    df[new_col] = df[new_col].astype(float)\n","\n","num_cols = df.select_dtypes(['int32', 'int64', 'float32', 'float64']).columns\n","df.select_dtypes(['int32', 'int64', 'float32', 'float64'])"]},{"cell_type":"markdown","metadata":{"id":"B1lSfGnMU0KV"},"source":["<a id=\"outlier\"></a>\n","## 2.6 Outlier Analysis and Treatment\n","\n","There are many ways to detect the outliers.<br>\n","Mostly used and hihgly efficient ways to detect the outliers are using z score and IQR.\n","1. Outlier detection using `z score` method: The data points for which the z score is greater than `3` are treated as outliers.\n","2. Outlier detection using `IQR`: The datapoints which are falling outside the range of q1 - 1.5iqr and q3 +1.5iqr.<br>\n","where `iqr = q3 - q1`."]},{"cell_type":"markdown","metadata":{"id":"qnFRLgO3U-fM"},"source":["1. Detect outliers using the z score for sugars variable"]},{"cell_type":"markdown","metadata":{"id":"H2Oaa33YEjY_"},"source":["* The very first step will be setting the upper and lower limit. This range stimulates that every data point will be regarded as an outlier out of this range. Let’s see the formulae for both upper and lower limits.\n","* Upper: Mean + 3 * standard deviation.\n","* Lower: Mean – 3 * standard deviation.\n"]},{"cell_type":"markdown","metadata":{"id":"TvG3pfl8FOoL"},"source":["* Here we are detecting how many outliers are there in the dataset based on the upper and lower limit that we set up just"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":982,"status":"ok","timestamp":1673382564099,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"Xz4Yymm1nk9A","outputId":"64aa0e25-0f4a-4804-82bb-e8b3e87f3fde"},"outputs":[],"source":["# iterate through df columns\n","for i in num_cols:\n","    # print column name\n","    print(i)\n","    # print upper limit of the column\n","    print(f\"Upper limit\",df[i].mean() + 3*df[i].std())\n","    # print lower limit of the column\n","    print(f\"lower limit\",df[i].mean() - 3*df[i].std())\n","    # get shape of outlier dataframe \n","    temp = df[(df[i] > df[i].mean() + 3*df[i].std()) | (df[i] < df[i].mean() - 3*df[i].std())].shape\n","    # print the Standard Deviation of the column\n","    print(f\"Standard Deviation: {df[i].std()}\")\n","    print(f\"shape of outlier dataframe: {temp}\")\n","    # get percentage of outlier data\n","    percentage = temp[0]/df.shape[0] * 100\n","    print(f\"Percentage of Outliers: {percentage}\")\n"]},{"cell_type":"markdown","metadata":{"id":"UxXqGPIvzJ5n"},"source":["The above output is the index for outlier datapoints.\n","\n","2. Detect outliers using the IQR method for sugars variable"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":956},"executionInfo":{"elapsed":520,"status":"ok","timestamp":1673381771682,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"_l_zJgoeHqju","outputId":"de657a48-f00d-4321-9018-ec3b72eada52"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1673382775405,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"KLFj-FGinOaH","outputId":"18597e24-d08f-4864-bc47-f6f6c2386f6a"},"outputs":[],"source":["for i in num_cols:\n","    print(i)\n","    q1 = np.percentile(df[i], 25, interpolation='midpoint')\n","    q3 = np.percentile(df[i], 75, interpolation='midpoint')\n","    iqr = q3 - q1\n","    ul = q3 +1.5*iqr\n","    ll = q1 - 1.5*iqr\n","    outliers = df[(df[i] > ul) | (df[i] < ll)]\n","    print(f\"Shape of outliers: {outliers.shape}\")\n","    print(f\"Percentage of outliers: {outliers.shape[0]/df.shape[0] * 100}\")\n"]},{"cell_type":"markdown","metadata":{"id":"NX56FKvKFYli"},"source":["* We can see there's quite a big number of outliers in our dataset.\n","* To remove these outliers we can use the code below"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":828,"status":"ok","timestamp":1673382973105,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"PzYg5WEOZRZY","outputId":"e50123df-feba-4e55-85b6-18212674120e"},"outputs":[],"source":["# iterate through df columns\n","for i in num_cols:\n","    # print column name\n","    print(i)\n","    # print upper limit of the column\n","    print(f\"Upper limit\",df[i].mean() + 3*df[i].std())\n","    # print lower limit of the column\n","    print(f\"lower limit\",df[i].mean() - 3*df[i].std())\n","    # get shape of outlier dataframe \n","    df = df[~(df[i] > df[i].mean() + 3*df[i].std()) | (df[i] < df[i].mean() - 3*df[i].std())]\n","\n","df"]},{"cell_type":"markdown","metadata":{"id":"LQ7S5KZwM4PH"},"source":["<a id=\"prep\"></a>\n","# 3. Descriptive Statistics\n","Within descriptive statistics, there are two measures used to describe the data: \n","1. Central tendency: It refers to the central position of the data (mean, median, mode)\n","2. Deviation: It describes how far spread out the data are from the mean. The deviation is most commonly measured with the standard deviation. "]},{"cell_type":"markdown","metadata":{"id":"bkUJ2lAjNjPv"},"source":["<a id=\"cte\"></a>\n","## 3.1. Measures of Central tendencies\n","\n","\n","Let's First start with the Central tendency.<br>\n","It mainly contains three operations :\n","1. Mean.\n","2. Median.\n","3. Mode.\n"]},{"cell_type":"markdown","metadata":{"id":"JdMbX8BdN38O"},"source":["<a id=\"mn\"></a>\n","### 3.1.1 Mean\n","The “Mean” is the average of the data.<br>\n","Average can be identified by summing up all the numbers and then dividing them by the number of observations.\n","\n","Mean = X1 + X2 + X3 +… +  Xn / n\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PaoslEztOIHI"},"source":["Find the mean of for all the columns.<br>\n","\n","Hint:- You can find the mean of columns using `mean` method from pandas dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1673005209995,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"I_Sy4drIJ16-","outputId":"09208335-c4a4-404d-ea08-14d1445e212f"},"outputs":[],"source":["df.mean()"]},{"cell_type":"markdown","metadata":{"id":"gBnWUr-5erMV"},"source":["<a id=\"mdn\"></a>\n","### 3.1.2 Median\n","The Median is the 50th percentile of the data. It is precisely the center point of the data.\n","\n","The Median can be identified by ordering the data and splitting the data into two equal parts and finding the number. It is the best way to find the center of the data."]},{"cell_type":"markdown","metadata":{"id":"HwkiK6d4xGtD"},"source":["Find the median for all the columns \n","\n","<b>Hint:-</b> There is median method is available in pandas dataframe. You can use it. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1673005211335,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"FOalrR0lJcy-","outputId":"ab1972c6-f24c-4b20-9a28-60483534f757"},"outputs":[],"source":["df.median()"]},{"cell_type":"markdown","metadata":{"id":"l53fWclKfLQV"},"source":["<a id=\"md\"></a>\n","### 3.1.3 Mode\n","* Mode is frequently occurring data or elements.\n","\n","* If an element occurs the highest number of times, it is the mode of that data. If no number in the information is repeated, then there is no mode for that data. There can be more than one mode in a dataset if two values have the same and highest frequency.\n","\n","* Outliers don’t influence the data.\n","\n","* The mode can be calculated for both quantitative and qualitative data."]},{"cell_type":"markdown","metadata":{"id":"JY0Ty-2OxR9s"},"source":["### Find the Mode for categorical variables.\n","\n","Hint :- You can use the `mode()` method to find mode of the given columns"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673005212359,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"N61qENNi8oJT","outputId":"f7072c79-b40d-49fa-c110-16a97db8664f"},"outputs":[],"source":["df['name'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1673005213189,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"pAAh2jwnFrZy","outputId":"610a5f3b-6465-4bd0-c9fa-01f6b019e026"},"outputs":[],"source":["df['name'].duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1673005213189,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"6pq0mCl--Zng","outputId":"b4720e43-c57e-471d-cf7b-816c35fa2e59"},"outputs":[],"source":["df['name'].nunique()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1673005213190,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"g6EkhUa9F2Xl","outputId":"04eab2a4-fd28-4b76-cd12-5ee82f6ed935"},"outputs":[],"source":["df['name'].mode()"]},{"cell_type":"markdown","metadata":{"id":"OYVxsaqbGBlm"},"source":["Categorical feature, name do not has any repetation all the entries are unique.<br> So it do not has mode."]},{"cell_type":"markdown","metadata":{"id":"kX5TD6kgLXfb"},"source":["### Find the Mode for numerical variables."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":420,"status":"ok","timestamp":1673383028302,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"ujtvtG_GFkUJ","outputId":"60e49a57-315a-4e5b-f2e3-691675c76f1b"},"outputs":[],"source":["num_features = df.select_dtypes(['int32', 'int64', 'float32', 'float64']).columns\n","num_features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":414,"status":"ok","timestamp":1673383034689,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"VIJIPjlfGpfT","outputId":"ce0de3a7-57f9-4a75-b6fd-377a71be5851"},"outputs":[],"source":["df_mode = []\n","# int_features = list(df.select_dtypes(include=['int64']).columns)\n","# float_features = list(df.select_dtypes(include=['float64']).columns)\n","# num_features = int_features + float_features\n","\n","num_features = df.select_dtypes(['int32', 'int64', 'float32', 'float64']).columns\n","for i in num_features:\n","  df_mode.append(df[i].mode().values)\n","\n","pd.DataFrame({'Name':num_features, \"Mode\":df_mode})\n","num_features"]},{"cell_type":"markdown","metadata":{"id":"KXH1wfQEJPvI"},"source":["* The above table shows the mode for all the columns in the dataset."]},{"cell_type":"markdown","metadata":{"id":"u390u-at0Zx9"},"source":["### limitations of Central tendencies\n","\n","1. mean is highly influenced by extreme values/outliers.\n","2. Mean is not a good representative of data for skewed distribution.\n","2. Measures of Central tendency gives only one representative value for each variables."]},{"cell_type":"markdown","metadata":{"id":"hJQ09_8Z_ciZ"},"source":["<a id=\"dd\"></a>\n","## 3.2 Measures of Dispersion\n","1. It describes the spread of the data.\n","2. Variance and Standard deviation gives the idea about distance of each point from mean the.\n","3. Standard deviation is the square root of variance."]},{"cell_type":"markdown","metadata":{"id":"rJDhTcuVxcwU"},"source":["<a id=\"rn\"></a>\n","### 3.2.1 Range "]},{"cell_type":"markdown","metadata":{"id":"xbg3loH4RWuD"},"source":["Range is the difference between maximum and minimum value.<br>\n","Find minimum and maximum values for variable, alcohol.<br>\n","Hint :- You can find the maximum and minimum values using `max()` and `min()` method from pandas. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZWw3_qWVaPU"},"outputs":[],"source":["df_max = []\n","df_min = []\n","df_range = []\n","for i in num_features:\n","  df_max.append(df[[i]].max())\n","  df_min.append(df[[i]].min())\n","  df_range.append(df[[i]].max() - df[[i]].min())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2goXUCfL_QS-","outputId":"cc303c15-54e3-4afc-c7fc-2f2e7fac8830"},"outputs":[],"source":["df_range"]},{"cell_type":"markdown","metadata":{"id":"bkobtYddBDNn"},"source":["Vitamin_a has the highest range which is 100000 while hydroxyproline has the least range 1.13."]},{"cell_type":"markdown","metadata":{"id":"7DyB1nXPT9XN"},"source":["You can get idea about range of values by finding the maximum and minimium values."]},{"cell_type":"markdown","metadata":{"id":"KG6YlsePl4bg"},"source":["Find the Numbers of Unique values in the column named \"alcohol\".<br>\n","You can find the number of unique values in the column using, `nunique()` method from pandas."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D7ykvG0XxmNl","outputId":"a01e735b-4b97-40c7-ae74-d2e8be36a7e8"},"outputs":[],"source":["df.nunique()"]},{"cell_type":"markdown","metadata":{"id":"F_8YE50uU_Tu"},"source":["<a id=\"var\"></a>\n","### 3.2.2 Variance\n","The variance is a measure of variability.<br> It is the average squared deviation from the mean.<br>\n","Varinace tells about how each point is far away from mean value.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QlCMaI_3zbHx"},"source":["Find the variance of the column named \"total_fat\".<br>\n","Hint :- You can use the `var()` method to find the variance of the given column."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yLo5pZ8JB0yX","outputId":"f280a528-1a9f-49e4-e79c-817c9a4cd024"},"outputs":[],"source":["df.var()"]},{"cell_type":"markdown","metadata":{"id":"ICSN1fEeWGe0"},"source":["<a id=\"sd\"></a>\n","### 3.2.3 Standard Derivation\n","Standard deviation is the square root of variance.<br>\n","The Standard deviation is the measure of how far the data deviates from the mean value.<br>\n","It is most common measure of spread of data.\n","<br>\n","\n","Hint :- You can find the Standard derivation using the `std` method.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tAaxzmPlB-ZL","outputId":"2d48c828-0852-459c-c669-be82771f2291"},"outputs":[],"source":["df.std()"]},{"cell_type":"markdown","metadata":{"id":"qBwOyav7xzQK"},"source":["#### Finding the central tendency and dispersion of data for the column \"alcohol\" using `describe()` method.\n","<ul>\n","<li> total numbers of rows in column</li>\n","<li> mean </li>\n","<li> standard derivation </li>\n","<li> Minimum values </li>\n","<li> Maximum values </li>\n","<li> 25%,50%,75% percentile values </li>"]},{"cell_type":"markdown","metadata":{"id":"Stz8AV6uWbSV"},"source":["You can use `describe()` method to find all the above things. \n","<br>\n","\n","You can read more about it from <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\"> This link </a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"elapsed":1168,"status":"ok","timestamp":1673383069363,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"dztIPWbcxkHB","outputId":"1a92cc32-5cbe-4767-ff3c-1eef3d30886c"},"outputs":[],"source":["df.describe()"]},{"cell_type":"markdown","metadata":{"id":"-Fzj8gYfzXXs"},"source":["<a id=\"cor\"></a>\n","### 3.2.4 Correlation\n"]},{"cell_type":"markdown","metadata":{"id":"1cKdCMmDXlqH"},"source":["Find the correlation between all the columns.<br>\n","\n","Hint:- You can use `corr()` method to find the correlationship between all the columns"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"pzXKOPVTzWyB","outputId":"d5228222-01a3-48e0-8067-da2dcc1bcda4"},"outputs":[],"source":["df.corr()\n"]},{"cell_type":"markdown","metadata":{"id":"1O1ldqr6hFSD"},"source":["There is highest positive correlation between saturated_fatty_acid and saturated_fat.<br>\n","There is highest negative correlation between calories and water."]},{"cell_type":"markdown","metadata":{"id":"1_AViSlA47wl"},"source":["**Heat Map**\n","\n","Heat Maps are graphical representations of data that utilize color-coded systems. The primary purpose of Heat Maps is to better visualize the volume of locations/events within a dataset and assist in directing viewers towards areas on data visualizations that matter most.\n","\n","Plot the heatmap for all the features in the given dataset.\n","\n","Hint : You can use `heatmap()` method from seaborn package to create heatmap.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":734},"id":"Avo8bKxH5SUi","outputId":"e142582c-73dd-414f-f80b-eae0a008133d"},"outputs":[],"source":["corr = df.corr()\n","_, ax = plt.subplots(figsize=(13,10)) \n","\n","# graph correlation matrix\n","_ = sns.heatmap(corr, ax=ax,\n","                xticklabels=corr.columns.values,\n","                yticklabels=corr.columns.values,\n","                cmap='coolwarm')"]},{"cell_type":"markdown","metadata":{"id":"29Cg-LKfYLbz"},"source":["The result of the correlation tells how each column is related to the other. \n","\n","The number varies from -1 to 1 where 1 means that there is a 1-to-1 relationship (a perfect correlation), and for this data set, each time a value went up in the first column, the other one went up as well.\n","\n","0.9 is also a good relationship, and if you increase one value, the other will probably increase as well.\n","\n","-0.9 would be just as good a relationship as 0.9, but if you increase one value, the other will probably go down.\n","\n","0.2 means NOT a good relationship, meaning that if one value goes up does not mean that the other will.\n","\n","What is a good correlation? It depends on the use, but I think it is safe to say you have to have at least "]},{"cell_type":"markdown","metadata":{"id":"sjorvpxrzoMi"},"source":["\n","<a id=\"viz\"></a>\n","# 5. Visualization"]},{"cell_type":"markdown","metadata":{"id":"TQAOZFApYYuQ"},"source":["<a id=\"hist\"></a>\n","# 5.1 Histogram\n","\n","histogram is a bar graph-like representation of data that buckets a range of classes into columns along the horizontal x-axis. The vertical y-axis represents the number count or percentage of occurrences in the data for each column. Columns can be used to visualize patterns of data distributions."]},{"cell_type":"markdown","metadata":{"id":"w1D7j8HWyxsg"},"source":["Find the distribution of the following all the numerical columns using histogram\n","\n","Hint :- You can plot the histogram using the `hist()` method of the pandas dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":896},"id":"Qbcgo6-K1Ca2","outputId":"7fe4e739-3a01-48bc-ee9b-c4d15dd476bd"},"outputs":[],"source":["plt.figure(figsize=(15,15))\n","\n","hist_df = df[num_features]\n","hist_df.hist(figsize=(15,15))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"yMA_BirYNCV2"},"source":["From above histogram, we can see that all the features are right skewed except for feature called water."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"JeU_KHIH03CA","outputId":"e6078d01-a784-498d-dd8e-1fb18f749358"},"outputs":[],"source":["px.histogram(x=df['total_fat']) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"PujxneDF16kF","outputId":"505cd153-5e7c-4c9d-bfb1-99246fb40b1a"},"outputs":[],"source":["px.histogram(x=df['protein']) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"_ZkPWcCu2D9y","outputId":"ab59e051-4f7e-4528-eadd-46e0ce4398b2"},"outputs":[],"source":["px.histogram(x=df['calories']) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"LloxC35z2O-F","outputId":"ac51711a-3881-41e9-ae60-0b74f1e709e4"},"outputs":[],"source":["px.histogram(x=df['cholesterol'])"]},{"cell_type":"markdown","metadata":{"id":"ii3r3vWtIb5Y"},"source":["The variables sugars, total_fat and protein are right skewed.\n","\n","**As the dataset is quite large, we have shown a few examples here. However, we encourage the learners to try with as many variables the can**"]},{"cell_type":"markdown","metadata":{"id":"DFP7t7XUY0QZ"},"source":["<a id=\"viz\"></a>\n","# 5.2 Count Plot\n","\n","A count plot can be thought of as a histogram across a categorical, instead of quantitative, variable.<br>\n","You can read more about `countplot()` on <a href=\"https://seaborn.pydata.org/generated/seaborn.countplot.html#:~:text=Show%20the%20counts%20of%20observations,compare%20counts%20across%20nested%20variables.\"> This link </a>."]},{"cell_type":"markdown","metadata":{"id":"4Cdvkma1ZBYx"},"source":["Plot a count plot for the first 50 rows of macro nutrients, protein, carbohydrate, total_fat.<br>\n","\n","Hint: -You can use the seaborn pakage from plotting the count plot and don't forget to slice the dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"dsA5rkzK2tSS","outputId":"b84bb992-0b04-4a14-99f5-82b9ff6b0288"},"outputs":[],"source":["plt.figure(figsize = (10,5))\n","sns.countplot(data=df[:50], x=\"protein\")\n","plt.title('Countplot for protein')\n","plt.xticks(rotation=90)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"3hJ8_fm5Nq_b","outputId":"9ce9dac0-5e65-4b07-83bb-4eefa493191b"},"outputs":[],"source":["plt.figure(figsize = (10,5))\n","sns.countplot(data=df[:50], x=\"carbohydrate\")\n","plt.title('Countplot for Carbohydrate')\n","plt.xticks(rotation=90)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"1cFwS-XUNzOO","outputId":"5714c677-4479-48c3-d3cd-35c23ef7bc0f"},"outputs":[],"source":["plt.figure(figsize = (10,5))\n","sns.countplot(data=df[:50], x=\"total_fat\")\n","plt.title('Countplot for total_fat')\n","plt.xticks(rotation=90)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"LCXMts4MPX6e"},"source":["* Protein content present in most of the food items in first 50 rows is 0.0. \n","* The carbohyderate level present in food items in first 50 rows is most of the time 0.0 or 6.25 or 42.6\n","* Most of the food items in first 50 rows has total_fat level upto 0.5 or 16.0. "]},{"cell_type":"markdown","metadata":{"id":"RbcwQJvmN_wg"},"source":["Plot a count plot for the last 50 rows of macro nutrients, protein, carbohydrate, total_fat."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"L4QErStGOCZI","outputId":"cf3ea633-7799-4736-dbd2-77d28128055c"},"outputs":[],"source":["plt.figure(figsize = (10,5))\n","sns.countplot(data=df.tail(50), x=\"protein\")\n","plt.title('Countplot for protein')\n","plt.xticks(rotation=90)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"U2yBxGblOCOR","outputId":"94990111-e628-4112-ec3d-004a4fe9a042"},"outputs":[],"source":["plt.figure(figsize = (10,5))\n","sns.countplot(data=df.tail(50), x=\"carbohydrate\")\n","plt.title('Countplot for Carbohydrate')\n","plt.xticks(rotation=90)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"id":"98ZLRYasOCCJ","outputId":"c4093afc-c2b0-4e1e-de5c-2e831ef7f0d4"},"outputs":[],"source":["plt.figure(figsize = (10,5))\n","sns.countplot(data=df.tail(50), x=\"total_fat\")\n","plt.title('Countplot for total_fat')\n","plt.xticks(rotation=90)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gUmA5_EDQFCR"},"source":["* Protein content present in most of the food items in last 50 rows is 23.37 or 29.59. \n","* The carbohyderate level present in food items in last 50 rows is most of the time 0.0.\n","* Most of the food items in last 50 rows has total_fat level upto 20. \n","\n","**As the dataset is quite large, we have shown a few examples here. However, we encourage the learners to try with as many variables the can**"]},{"cell_type":"markdown","metadata":{"id":"KQ5_TmpPZYVo"},"source":["<a id=\"sk\"></a>\n","# 5.3 Skewness and Kurtosis\n","\n","Skewness is the measure of the asymmetry of the distribution of data.<br>\n","The data is not symmetrical (i.e) it is skewed towards one side.<br>\n","While Kurtosis is the measure of describing the distribution of data.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JjAD5uOVaHYk"},"source":["Find the Skewness and Kurtosis for all the columns.<br>\n","\n","You can find the Skewness and Kurtosis using `kurt()` and `skew()` method which are available in pandas dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iky4KLfe5x1k","outputId":"4b282485-9de6-4bac-f9b8-9abd837a8db6"},"outputs":[],"source":["df.kurt()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hy1v7GcYRQmP","outputId":"da6a93b5-1997-4fe3-e557-ee050b0d80cb"},"outputs":[],"source":["# list(df.kurt().values)\n","pd.set_option('display.max_rows', 74)\n","pd.DataFrame(df.kurt()) "]},{"cell_type":"markdown","metadata":{"id":"-IAwhdYUIwmO"},"source":["* A distribution with kurtosis < 3 follows platykurtic distribution and with kurtosis > 3 follows leptokurtic distribution.<br>\n","* In comparison to a normal distribution, a platykurtic distribution will have thinner tails while leptokurtic distribution will have flatter tails.<br>\n","* A statistical distribution with negative excess kurtosis is also referred to as \"platykurtic.\"<br>\n","* The extreme occurrences are less frequent than in a normal distribution for platykurtic distribution and most frequent than in a normal distribution for leptokurtic distribution .\n","* The features calories, protein, glutamic_acid, histidine isoleucine, leucine, lysine, threonine, tyrosine, carbohydrate, water has the platykurtic distribution while rest of the features are said to be leptokurtic.<br>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYCAxSKD6UOe","outputId":"ad8c028f-6c5c-48c1-edb7-f055742cff34"},"outputs":[],"source":["df.skew()"]},{"cell_type":"markdown","metadata":{"id":"Mh0tcco0JXBb"},"source":["* When a data set is symmetrical, its mean, median, and mode are all equal. A data set is said to be skewed in that direction if one side of the middle has more extreme individuals than the other.\n","* None of the feature has symmetrical distribution since the skewness is not 0 for any of the fature.<br>\n","* The left side of the peak of a negatively skewed distribution is longer than the right.\n","* The feature, water is negatively skewed since its skewness value is negative.\n","* galactose and caffeine are highly right skewed features."]},{"cell_type":"markdown","metadata":{"id":"HDGU0qfdaX6O"},"source":["<a id=\"sp\"></a>\n","# 5.4 Scatter plot\n","\n","The Scatter plot is used to find the relationship between two parameters in other words, we can say the scatter plot is used to show us how two variables are related to each other."]},{"cell_type":"markdown","metadata":{"id":"HJNOtlXcbJoW"},"source":["Plot a scatter plot for columns \"water\" v/s \"sugars\" to find relationship between them.<br> \n","\n","Hint :- You can use the `scatterplot()` method from the seaborn pakage for drawing scatterplot.\n","<br>\n","\n","You can read more about it on <a href=\"https://seaborn.pydata.org/generated/seaborn.scatterplot.html\">This link </a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"jLA9osxr8DvY","outputId":"3e996b29-f178-44a7-e969-429e080543eb"},"outputs":[],"source":["sns.scatterplot(data=df, x=\"water\", y=\"sugars\")"]},{"cell_type":"markdown","metadata":{"id":"-Xc8FTXf71QZ"},"source":["The food items which have highest water level have less sugar level for most of the times."]},{"cell_type":"markdown","metadata":{"id":"O4um4lVlLj2R"},"source":["The above method is for ploting scatter plot for a limited variables/columns. \n","\n","Here we can see how plot a scatter plot for all columns in the dataset.\n","We can use `pairplot()` method provided by seaborn to get scatter plots of all the columns in a dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"puh3NtyJxPgr"},"outputs":[],"source":["sns.pairplot(df)"]},{"cell_type":"markdown","metadata":{"id":"r1bKP2P55XSF"},"source":["<a id=\"dp\"></a>\n","# 5.5 Density Plot\n","\n","Like a smoother histogram, a density plot shows data. <br>\n","In density plots, the kernel density estimate is typically used to display the probability density function of the variable. <br>\n","To get a smooth density estimate for the whole set of data, a continuous curve—the kernel—is created.<br>\n","Density plot helps to get the distribution of variable in a feature."]},{"cell_type":"markdown","metadata":{"id":"0Ipoed0wK0FL"},"source":["Plot the density plot for column, sugars.\n","\n","Hint :- You can use the `density()` method from the seaborn pakage for drawing scatterplot. We can do the same plot using seaborn with this code : \n"," `sns.kdeplot(data=df, x=\"sugars\")`\n","<br>\n","\n","You can read more about it on <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html\">This link </a>\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"RuoLQhE45a5D","outputId":"1c671d39-87c3-4c4d-a0d8-9b509360ce5d"},"outputs":[],"source":["df['sugars'].plot.density()\n","plt.title('Density Plot for sugars')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"7DQ08-EhLx86"},"source":["Variable sugars is right skewed.\n","\n","**As the dataset is quite large, we have shown a few examples here. However we encourage the learners to try with as many variables the can**"]},{"cell_type":"markdown","metadata":{"id":"zkMmrNGkbl5Q"},"source":["<a id=\"bp\"></a>\n","# 5.6 Box Plot\n","\n","The box plot (or box-and-whisker plot) shows the distribution of quantitative data in a way that facilitates comparisons between  the variables or across levels of a categorical variable.<br> The box shows the quartiles of the dataset while the whiskers extend to show the rest of the distribution, except for points that are determined to be “outliers” using a method that is a function of the interquartile range."]},{"cell_type":"markdown","metadata":{"id":"Wm2CltXDdHxe"},"source":["Draw a boxplot for the columns \"water\" and \"sugars\".<br>\n","\n","Hint :- You can use `boxplot` method of pandas dataframe to create boxplot for it."]},{"cell_type":"markdown","metadata":{"id":"frM1CHSN9R7v"},"source":["Plotting boxplot on single feature"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"ux5ZWtFV8p-Q","outputId":"9c42668f-aad3-489a-8727-bdc4fa465129"},"outputs":[],"source":["df[['water','sugars']].boxplot()"]},{"cell_type":"markdown","metadata":{"id":"YP7Fkr5fM6YL"},"source":["The variable water has no outliers.<br>\n","The variable sugars has many outliers."]},{"cell_type":"markdown","metadata":{"id":"5KR44L29MV7o"},"source":["The above method is for ploting box plot for a limited variables/columns. \n","\n","Here we can see how plot a box plot for all columns in the dataset.\n","We can use `boxplot()` method provided by pandas to get box plots of all the columns in a dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"K2l_3_7dlpXt","outputId":"c9e3112f-ac92-40be-85d1-b871f78b11c4"},"outputs":[],"source":["plt.figure(figsize=(60,15))\n","\n","hist_df = df[num_features]\n","              \n","hist_df.boxplot(figsize=(50,50))\n","plt.xticks(rotation='vertical')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"bIDWX7-HeO1Z"},"source":["<a id=\"bxp\"></a>\n","# 5.7 Boxen Plot\n","The boxen plot is an enhanced version of boxplot. It provides more information about the shape of the distribution and also helps to get the outliers present in the dataset more clearly than that of boxplots."]},{"cell_type":"markdown","metadata":{"id":"Vxu6TF7S9cMe"},"source":["Plot three diffrent boxenplot for following columns using `seaborn` pakage.<br>\n","<ul>\n","<li>sugars</li>\n","<li>water</li>"]},{"cell_type":"markdown","metadata":{"id":"N9O50OBJfbBx"},"source":["Hint :- You can use the `boxenplot()` method from seaborn pakage to create the boxenplot."]},{"cell_type":"markdown","metadata":{"id":"xf_K6QwV2oZp"},"source":["To plot individual boxenplot we'll pass one column value."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"mTEBApMs6XYW","outputId":"04d51d0f-4d45-4b92-f23b-85d14789a2b8"},"outputs":[],"source":["sns.boxenplot(x=df['sugars'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"5xoPHlc7-j73","outputId":"b8f26722-08a0-43a1-8743-895b13a9d058"},"outputs":[],"source":["sns.boxenplot(x=df['water'])"]},{"cell_type":"markdown","metadata":{"id":"_bMZbDtVM0XY"},"source":["The above method is for ploting boxen plot for a limited variables/columns. \n","\n","Here we can see how plot a boxen plot for all columns in the dataset.\n","We can use `boxenplot()` method provided by seaborn to get boxen plots of all the columns in a dataset."]},{"cell_type":"markdown","metadata":{"id":"sHEW0fCQkufp"},"source":["Plotting the boxen plot for all features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334},"id":"02etUlpWgnEk","outputId":"5345c58f-7c2e-4220-8d38-e0b8ff45008d"},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(70,20))\n","p = sns.boxenplot(data=hist_df)\n","p.set(ylabel='My yLabel', xlabel='My xLabel')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gv5YVKFX076N"},"source":["<a id=\"barp\"></a>\n","# 5.8 Bar Plot\n","A bar plot represents an estimate of central tendency for a numeric variable with the height of each rectangle and provides some indication of the uncertainty around that estimate using error bars.<br>\n","You can read more about it on <a href=\"https://seaborn.pydata.org/generated/seaborn.barplot.html\">This link </a>"]},{"cell_type":"markdown","metadata":{"id":"-fJqsIQi1hf8"},"source":["Plot the barplot for variance of  features like, vitamin_b12, vitamin_e, fiber, fructose, glucose, lactose, sucrose, alcohol, ash.<br>\n","\n","Hint : You can use `barplot()` method from seaborn package to create barplot."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":674},"executionInfo":{"elapsed":5220,"status":"ok","timestamp":1673384876018,"user":{"displayName":"Parth","userId":"13715439257883413306"},"user_tz":-330},"id":"43NCfHMt1giC","outputId":"e5b96ca8-1ab9-422c-d1b9-726aae4a970e"},"outputs":[],"source":["# Get the vaariance for selected features\n","# variance = df[['vitamin_b12', 'vitamin_e', 'fiber', 'fructose', 'glucose', 'lactose', 'sucrose', 'alcohol', 'ash']].var()\n","variance = df[num_cols].var()\n","var_df = df[num_cols]\n","\n","# Get column with max variance\n","print(variance.idxmax())\n","\n","# Get column with min variance\n","print(variance.idxmin())\n","\n","# Plot the bar plot\n","plt.figure(figsize=(15,8))\n","ax = sns.barplot(x=variance.index.tolist(), y=variance.values.tolist())\n","# Rotate X axis coordinates vertically.\n","plt.xticks(rotation='vertical')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Fj5bJbHnN26o"},"source":["The variance for variable, vitamin_a is very high while galactose has very less variance."]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
